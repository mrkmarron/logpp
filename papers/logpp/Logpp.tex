\documentclass[sigplan,10pt,review]{acmart}

\settopmatter{printfolios=true}

\usepackage{times}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{array}
\usepackage{multirow}
\usepackage{balance}
\usepackage{paralist}
\usepackage{graphicx,color}

\usepackage{listings} 
\usepackage{color} %use color

\newtheorem{design}{Design Principle}

\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

%define Javascript language
\lstdefinelanguage{JavaScript}{
keywords={typeof, new, true, false, catch, function, return, null, undefined, try, catch, switch, var, if, in, while, do, else, case, break},
keywordstyle=\color{blue}\bfseries,
ndkeywords={class, export, boolean, throw, implements, import, this},
ndkeywordstyle=\color{darkgray}\bfseries,
identifierstyle=\color{black},
sensitive=false,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{purple}\ttfamily,
stringstyle=\color{red}\ttfamily,
morestring=[b]',
morestring=[b]"
}
 
\lstset{
language=JavaScript,
extendedchars=true,
basicstyle=\footnotesize\ttfamily,
showstringspaces=false,
showspaces=false,
numbers=left,
numberstyle=\footnotesize,
numbersep=9pt,
tabsize=2,
breaklines=true,
showtabs=false,
captionpos=b,
xleftmargin=0.5cm
}

\newcommand{\projn}{\textsc{Log++}\xspace}
\newcommand{\ourtitle}{\projn Logging for a Cloud-Native World} 

\newcommand{\todo}[1]{{\color{red}#1}}

\newcommand{\eg}{\hbox{\emph{e.g.}}\xspace}
\newcommand{\ie}{\hbox{\emph{i.e.}}\xspace}
\newcommand{\etc}{\hbox{\emph{etc.}}\xspace}

\newcommand\bench[1]{\textsf{\small #1}}
\newcommand{\niceunitkloc}{\,{\small kloc}\xspace}
\newcommand{\niceunitkb}{\,{\small KB}\xspace}
\newcommand{\niceunitmb}{\,{\small MB}\xspace}
\newcommand{\niceunitsec}{\,s\xspace}
\newcommand{\niceunitpct}{\,\%\xspace}

\newcommand{\codelines}[1]{#1\,kloc\xspace} 

\newcommand{\console}[1]{\texttt{\small #1}}

\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}

\begin{document}

%\toappear{Draft Document -- \url{https://github.com/mrkmarron/logpp}}

%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmConference[Submission '18]{Submission}{\url{https://github.com/mrkmarron/logpp}}{}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}

\title{\ourtitle}

\author{Mark Marron}
\affiliation{
  \department{Microsoft Research}              %% \department is recommended
  \institution{Microsoft}            %% \institution is required
  \streetaddress{Street1 Address1}
  \country{USA}                    %% \country is recommended
}
\email{marron@microsoft.com}          %% \email is recommended

\begin{abstract} 
Logging is a fundamental part of the software development and
deployment lifecycle but logging support is often provided as an afterthought 
via limited library APIs or third-party modules. Given the critical
nature of logging in modern cloud, mobile, and IoT development workflows, the unique needs of the APIs involved,
and the opportunities for optimization using semantic knowledge, we argue logging should
be included as a central part of the language and runtime designs. This paper
presents a rethinking of the logger for modern \emph{cloud-native} workflows. 

Based on a set of design principles for modern logging we build a logging system,
that supports near zero-cost for disabled log statements, low cost lazy-copying 
for enabled log statements, selective persistence of logging output, unified control 
of logging output across different libraries, and DevOps integration for use with 
modern cloud-based deployments. To evaluate these concepts we implemented the \projn 
logger for Node.js hosted JavaScript applications.
\end{abstract}

\maketitle

\section{Introduction} 
\label{sec:intro}
Logging has always been a important tool for software developers in
understanding their applications~\cite{logdebug,logdebug2,logstudy}. 
However, as DevOps oriented workflows have
become more prevalent, logging is becoming an even larger consideration when
building applications~\cite{logstudy,logstudy2}. A key area driving this shift is the use of cloud-based
applications and the integration of application monitoring dashboards, such as
Stack Driver~\cite{StackDriver}, NSolid~\cite{NSolid}, or
AppInsights~\cite{AppInsights}, which ingest logs from an application, correlate
this information with other aspects of the system, and provide this in a useful
dashboard format for developers. The additional value provided by these
dashboards and the ability to quickly act on this data makes the inclusion of
rich logging data an integral part of an applications development.

Existing logging library implementations, as provided via core or third party
libraries, are unable to satisfactorily meet the demands of logging in modern
applications. As a result developers must use existing libraries with care to
limit undesirable logging related performance impacts~\cite{learnlog} and \emph{log spew}~\cite{learnlog,logstudy2}, work 
to control logging output from other modules to the appropriate channels, and figure
out how to effectively parse the data that is written from various sources.
Consider the following sample JavaScript code in~\autoref{fig:introExample} 
which illustrates concrete issues encountered by Node.js~\cite{Node} developers today.

\begin{figure*}[t]
\lstinputlisting[language=JavaScript,basicstyle=\small]{Code/introExample.js}
\caption{Example logging usage in JavaScript}
\label{fig:introExample}
\end{figure*}

A major issue with logging is the potential for the accidental introduction 
of serious performance problems though seemingly benign activities~\cite{logdebug,logdebug2,logstudy,learnlog,logstudy2}. In 
existing logging framework even if a given logging level is disabled, 
as \texttt{debug} and \texttt{trace} levels usually are, the code to generate 
and format the log message is still executed. This can either be due to eager 
evaluation semantics of the source language or due to limitations in compiler 
optimizations for dead-code elimination in languages with workarounds such as 
macros. This results in code that looks like it will not be executed but that in 
reality incurs large parasitic costs and can be seen in the \texttt{logger.debug} 
statement in the example, which at the default level does not print to the log, but will
still result in the creation of the literal object and generation of a format
string on every execution of the loop. This cost leads developers to defensively
remove these statements from code instead of depending on the runtime to
eliminate their costs when deploying the application.

Next is the issue of \emph{log spew}~\cite{learnlog,logstudy2} where logging at a detailed level, which 
may be desireable for debugging when an issue occours, fills the log with 
large quantities of uninteresting noise output. An example of this is the 
\texttt{logger.info} message about the args and result of the \texttt{check} 
call in \autoref{fig:introExample}. In the case of a successful execution the content of this log statement 
is not interesting and the cost of producing this plus the increased noise in 
the logfile is pure overhead. However, if the \texttt{check} statement fails 
then having this information about what events led up to the failure may be 
critical in diagnosing/fixing the issue. In current logging frameworks this is 
an unavoidable conundrum and, in any case where the trace history is needed, 
the logging statements must be added and the cost/noise accepted as a cost.

The combination of verbose logging and the trend towards including critical, but 
extensive, metadata such as timestamps and host information in log messages further 
drives concerns about the performance of logging. Computing a timestamp or a 
hostname string is inexpensive but the cost of formatting them into a message is 
non-trivial can can add up over thousands or millions of log messages resulting 
in unexpected performance degradation. 

Modern developer practices around logging frequently involve post processing 
of log data into analysis framework like the Elastic stack~\cite{elastic} or Splunk~\cite{splunk}. 
However, free form specification of message formats, as seen in \texttt{printf} or 
concatenated value styles, are not ammenable to machine parsing. Modern logging 
frameworks, log4j~\cite{log4j}, pino~\cite{pino}, bunyan~\cite{bunyan}, etc. 
provide some support for consistently formatting and structuring output but
fundamentally this problem is left as a problem development teams need to solve
via coding conventions and reviews.

The final issue we consider is the growing pain of integrating multiple software 
modules, each of which may use a different form of logging. In our running example 
we have \texttt{console.log} writing to the \texttt{stdout} and a
popular framework called \texttt{Winston} which has been configured to write to
a file. As a result some log output will appear on the console while other
output will end up in a file. Further, if a developer changes the logging output
level for \texttt{Winston}, from say \texttt{info} to \texttt{warn}, this will
not change the output level of the \texttt{console} output. Developers can work
around this to some degree by enforcing the use of a single logging framework
for their code but they will not always be able to control the frameworks used
by external libraries.

To address these issues we propose an approach where logging is viewed as a first 
class feature in the design/implementation of a programming language and runtime 
instead of simply another library to be included. Taking this view enables us to 
leverage language semantics, focused compiler optimizations, and semantic knowledge 
in the runtime to provide a uniform and high performance logging API.

\noindent
The contributions of this paper include:
\begin{itemize}
\item The view that logging is a fundamental aspect of programming and should be
included as a first class part of language, compiler, and runtime design.

\item A novel dual-level approach to log generation and writing that allows a
programmer to log execution data eagerly but only pay the cost of writting it to
the log if it turns out to be interesting/relevant.

\item Using this dual-level approach we show how to seperate and support the 
desire to use logging for both debugging when an error condition is encoutered 
and for telemety purposes to monintor general application behavior. 

\item A suite of innovative log format and log level management techniques that 
provide a consistent and unified log output that is easy to manage and feed into 
other tooling.

\item An implementation in Node.js to demonstrate that key ideas can be applied 
to existing languages/runtimes and to provide an production quality implementation 
for use in performance evaluations.
\end{itemize}

\section{Design}
\label{sec:design}
\input{design}

\section{Implementation}
\label{sec:implementation}
\input{implementation}

\section{Evaluation}
\label{sec:evaluation}
\input{evaluation}

\section{Related Work}
\label{sec:relwork}
While logging is a fundamental part of many software development workflows it has 
received relatively little attention overall from the academic community and, to the 
best of our knowledge, there is no prior work explicitly on the design of the core 
logging framework. 

\paragraph{Logging Practices:}
\noindent
The closest theme of prior research is focused on empirical investigation of logging 
use in practice and tools to support good logging practices~\cite{logstudy,logstudy2}. 
Using a large scale evaluation of OSS projects~\cite{logstudy} studied code changes 
involving logging code to understand how and why developers were using logging. 
Work on closed source applications~\cite{logstudy2} reached many of the same conclusions. 
These studies provided valuable insights which were used in distilling the design 
principles used in this work.

\paragraph{Improved Logging:}
\noindent
A larger area of work has been into techniques to support best practices for 
logger use. From a type system perspective~\cite{tyepcheckprintf} developed 
a type system and checker to ensure format specifiers and their arguments were 
well typed. Work in and LCAnalyzer~\cite{logginganti} proposes 
techniques to help developers with finding poor logging 
uses. Other work develops tools, such as  LogAdvisor~\cite{learnlog}, LogEnhancer~\cite{LogEnhancer}, 
and ErrLog~\cite{ErrLog}, which help developers identify locations and values which should 
be logged to support later diagnostics or analysis operations.

\paragraph{Log Analysis:}
\noindent
Work on the topic of using logs to support other software development activities is 
more extensive. This work includes post mortem debugging~\cite{loganalysis,sherlog,autolog}, anomaly 
detection~\cite{detection}, feature use studies~\cite{twitter}, and automated analysis of performance 
issue root causes~\cite{performance}. 
This body of work highlights the potential value of high quality logging data and the 
opportunities for research and tooling that depends on it.

\section{Conclusion}
This paper introduced a set of design principles for logging with the view that 
logging is a fundamental part of the software development and deployment lifecycle. 
By thinking of logging this way and how it can be closely coupled with the rest of the 
language and runtime for best performance and usability we developed a novel logging 
system with several innovative features. The first is a unique multi-level logging 
system that allows for simultaneous high fidelity debug oriented logging and low data 
rate telemetry logging. Next, by integration with the Node.js runtime, we showed how 
to implement near zero-costs disabled log statements, low cost lazy-copying 
for enabled log statements, background thread formatting, unified control 
of logging output across different libraries, and API design to optimize common logging 
tasks. As a result \projn outperforms existing state of the art logging frameworks and 
represents an important development in advancing the state of the art for 
modern modern cloud, mobile, and IoT development workflows.

\section*{Acknowledgments}
I would like to thank Matteo Collina, Matthew C. Loring, and Mike Kaufman for their insights into logging and 
useful feedback on this work. Thanks to Arunesh Chandra for his help with N-API and thoughts on how to 
use it effectively.

\balance

{
\raggedright 

\bibliography{bibfile} 
}


\end{document}
