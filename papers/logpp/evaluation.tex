% !TeX root = Logpp.tex
Given the implementation of \projn from~\autoref{sec:implementation} we now shift 
to evaluating how well the resulting system meets the design goals outlined in~\autoref{sec:design}.\\

\noindent
For this evaluation we use four of microbenchmarks with $10$k iterations: 

\begin{lstlisting}[language=JavaScript,basicstyle=\scriptsize,numbers=none]
//Basic
log.info("hello world -- logger")
//String
log.info("hello %s", "world")
//Compound
log.info("hello %s %j %d", "world", { obj: true }, 4)
//Compute
log.info("hello at %j with %j %n -- %s", 
         new Date(), ["i", { f: i, g: "#" + i }], 
         i - 5, (i % 2 === 0 ? "ok" : "skip"))
\end{lstlisting}

\noindent
We also use a server based on the popular \emph{express}~\cite{} framework 
which provides a \emph{REST} API for querying data on the S\&P 500 companies.

All of the benchmarks are run on an Intel Xeon E5-1650 CPU with 6 cores at 3.50GHz, 32GB of RAM, and a SSD. 
The software stack is Windows 10 (17134) and Node v10.0.

\subsection{Microbenchmarks}
Our first evalaution is with current state of the art logging approaches in 
Node.js. These include the builtin \texttt{console} methods, the \texttt{debug}~\cite{debuglogger} 
module, the \texttt{bunyan}~\cite{bunyanlogger} logger, and the \texttt{pino}~\cite{pinologger} logger.

\begin{table}[t]  
    \centering
    {\small
    \begin{tabular}{l | r r r r }
    Program       & \bench{Basic}  & \bench{String}   & \bench{Compound}  & \bench{Compute} \\
    \hline
    Console       & $883$ms & $852$ms & $1064$ms & $1239$ms \\
    Debug         & $202$ms & $200$ms & $282$ms  & $469$ms \\
    Bunyan        & $477$ms & $531$ms & $603$ms  & $920$ms \\
    Pino          & $188$ms & $190$ms & $296$ms  & $630$ms \\
    Log++         & $89$ms  & $93$ms  & $155$ms  & $304$ms \\
    \hline
    Speedup & $2.1$-$9.9\times$ & $2.0$-$9.2\times$ & $1.8$-$6.9\times$ & $2.1$-$4.1\times$ \\
    \end{tabular}
    }
    \vspace{2mm}
    \caption{Timings for each logging framework on $10$k iterations with given format. 
    Speedup is the min-max speedup relative to the other logging frameworks.}
    \label{tab:microcompare}
\end{table}

The results in~\autoref{tab:microcompare} show the wide performance variation across logging 
frameworks (spanning nearly a factor of $10\times$). Accross all benchmarks \projn is consistently 
the fastest logger, by a factor of at least $1.8$-$2.1\times$, when compared to the best performing 
of the existing logging frameworks.

\subsection{Logging Optimization Impacts}
To understand how much each of our design choices and optimizations contributed to 
this performance we look at the performance impacts of specific features in \projn. 

\begin{table}[t]  
    \centering
    {\small
    \begin{tabular}{l | r r r r }
    Program       & \bench{Basic}  & \bench{String}   & \bench{Compound}  & \bench{Compute} \\
    \hline
    Log++         & $89$ms  & $93$ms  & $155$ms  & $304$ms  \\
    Sync-Lazy     & $220$ms & $216$ms & $389$ms  & $636$ms  \\
    Sync-Strict   & $659$ms & $788$ms & $1035$ms & $1323$ms \\
    Levels (50\%) & $67$ms  & $72$ms  & $137$ms  & $223$ms  \\
    Levels (33\%) & $61$ms  & $65$ms  & $129$ms  & $189$ms  \\
    \end{tabular}
    }
    \vspace{2mm}
    \caption{ASDF}
    \label{tab:featureeval}
\end{table}

Lets do some microbencharks on logging and break down the impact of various 
implementation/design ideas...

enabled full

disabled

multi-level impact

expando impact

\begin{table}[t]  
    \centering
    {\small
    \begin{tabular}{l | r r r r }
    Program       & \bench{Host}  & \bench{App}   & \bench{Wallclock}  & \bench{Timestamp} \\
    \hline
    Explicit      & $8533$ms & $65$ms & $192$ms & $41$ms \\
    Expando       & $33$ms   & $32$ms & $41$ms  & $36$ms \\
    \end{tabular}
    }
    \vspace{2mm}
    \caption{ASDF}
    \label{tab:expando}
\end{table}

\subsection{Logging Performance}
The previous sections evaluated the performance of \projn with respect to other 
loggers on the core logging tasks and explored the impacts of various design 
choices using microbenchmarks. This section evaluates the impact of logging on 
a lightweight \emph{REST} API service that supports querying data on S\&P 500 
companies. 

We use \emph{autocannon}~\cite{autocannon} in the default load generation 
setting to create a heavy load on the service to stress the logger performance.
For comparision we include the builtin \texttt{console} methods 
and the \texttt{pino}~\cite{pinologger} logger in addition to \projn in the defualt 
setting.

This application highlights the tension between using logging as a telemetry source 
v.s. a diagnostic tool. We updated it to use two logging levels, \texttt{DETAIL} 
and \texttt{INFO}. In the default runs we log at both levels and include a case, 
\emph{levels}, where \projn logs in-memory for the higer detail level but only 
emits at the lower level.

\begin{table}[t]  
    \centering
    {\small
    \begin{tabular}{l | r r r }
    Logger       & Latency (avg) & Latency (stdev) & Requests/s (avg) \\
    \hline
%    No Logging     & $0.14$ms & $0.55$ms & $12,011$ \\
    Console        & $1.18$ms & $0.83$ms & $6668$   \\
    Pino           & $0.89$ms & $0.70$ms & $8133$   \\
    Log++          & $0.67$ms & $0.80$ms & $8645$   \\
    Log++ (off)    & $x.xx$ms & $x.xx$ms & $xxxx$   \\
    Log++ (levels) & $0.58$ms & $0.77$ms & $8958$   \\
    \end{tabular}
    }
    \vspace{2mm}
    \caption{Logging performance on \emph{REST} service for \texttt{console.log}, 
    \texttt{pino} and \texttt{Log++} (both enabled and off). Also modified to take advantage of the \texttt{Log++} 
    multi-level logging functionality in the \emph{Log++ (levels)} row. Average and 
    standard deviation values for response latencies are shown along with the average 
    number of requests served per second.}
    \label{tab:server}
\end{table}

The results in~\autoref{tab:server} show that using a logging framework designed 
for modern development needs and built with performance in mind can have a 
substantial impact on an application. In terms of reponses processed per second 
\projn increses the server throughput by $30\%$ from $6668$ to $8645$ requests 
per second. Further, \projn decreses the response time by $43\%$ 
from $1.18$ms to $0.67$ms. Despite using in-memory buffers and batched processing, 
which could in theory increased latency variability, the standard deviation of 
the responses actually decreases by $0.03$ms as well.

The results in~\autoref{tab:server} also show that, in addition to the improvements 
seen by using \projn as a drop in replacement, it is possible to further improve the 
logger behavior by refactoring the logging statements to take advantage of the 
multi-level logging capabilities. In the \emph{Log++ (levels)} the application is 
changed to write log statements that are relevant for debugging, but not for general 
telemetry, to be at the \texttt{DETAIL} level. This results in their being stored in 
the in-memory buffer, if needed for diagnostics, but not formatted and emitted. As 
a result the throughput increases a further $4\%$ to $8958$ and the latencey goes 
down an additional $13\%$ to $0.58$ms on average.

\subsection{Logging Data Size}
The final metric we evaluate is how \projn can be used to reduce the amount of 
storage and network capcity that is consumed by logging data. ASDF

\begin{table}[t]  
    \centering
    {\small
    \begin{tabular}{l | r r }
    Logger        & Raw & Compressed \\
    \hline
    Log++          & $25,404$kb & $1,378$kb \\
    Log++ (levels) & $11,760$kb & $841$kb   \\
    \end{tabular}
    }
    \vspace{2mm}
    \caption{Log size on \emph{REST} service for \texttt{Log++}
    and modified to take advantage of the \texttt{Log++} 
    multi-level logging functionality in the \emph{Log++ (levels)} row. Raw 
    logging output size (\emph{Raw} column) and log data size after deflate 
    compression (\emph{Compressed} column).}
    \label{tab:compress}
\end{table}

study of simplified output log and reduction in storage/transport sizes -- 
e.g., save XXMB of traffic/storage per day kind of thing.

compression impact
