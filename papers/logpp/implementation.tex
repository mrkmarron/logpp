% !TeX root = Logpp.tex
Given the design principles outlined in \autoref{sec:implementation} we now 
present the implementation of \projn\footnote{\projn sources available at 
\url{https://github.com/mrkmarron/logpp}} which realizes these goals in a logger 
for the \texttt{Node.js}~\cite{Node} runtime. It is possible to implement many 
of the features needed to satisfy our design goals as a library or using the 
native API extension bindings (N-API~\cite{NAPI}) but others require core 
runtime support. For these core changes we modify the ChakraCore JavaScript 
engine and core Node implementation directly.

\subsection{Implementation Overview}
The logging system is split into five major components that (1) manage the 
global logger states, message filters, message formats, and configurations (2) the message processor and in-memory buffer 
(3) the emit filter and processor (4) the formatter (5) and finally the transports. These 
components and the relations between them are shown in \autoref{fig:arch} and 
explained in detail in the rest of the section. 

\begin{figure*}[t]
\begin{minipage}[b]{0.47\textwidth}
    \lstinputlisting[language=JavaScript,basicstyle=\scriptsize]{Code/runningExample.js} 
    \caption{Running example main app code}
    \label{fig:appmain}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
    \lstinputlisting[language=JavaScript,basicstyle=\scriptsize]{Code/runningExampleSub.js}
    \caption{Running example submodule code}
    \label{fig:appsub}
\end{minipage}
\end{figure*}

\subsection{JavaScript Implementation}
\label{subsec:jsimpl}
\paragraph{Log State Manager}
\noindent
The first component we look at in the implementation is the global log state 
manager. This component is responsible for tracking all of the loggers that 
have been created, which one of them (if any) is the root logger, the enabled logging levels + 
categories, and the message formats which have been defined. The loggers are shown as $L_{\text{root}}$ 
and $L_{\text{c1}} \ldots L_{\text{c1j}}$ in  \autoref{fig:arch} and each one is associated with a Level Filter 
that controls which levels are enabled/disabled for it. The global category filter controls which categories are 
enabled/disabled on a global basis.

As seen in the example code there be many loggers 
created in different parts of the application. One logger, named ``app'', is created on line 
2 of the main application in \autoref{fig:appmain} while a second, named ``foo'', is created 
in the module \texttt{foo.js} in \autoref{fig:appsub} which is included from 
the main \texttt{app.js} file. As stated in \emph{design principle 5} we 
do not want the included sub-module \texttt{foo.js} to be able to, unexpectedly, 
change the logging level for the main app (the call to \texttt{setOutputLevel} on 
line 9). We also allow the root logger to enable/disable log outputs 
from these subloggers. 

To support these features the \projn logger keeps a list of all created loggers 
and a special \emph{root logger} which is the first logger created in the main 
module of the application. When updating logging levels or creating a new logger 
we check if the action is coming from the root logger and, if not, either convert 
the call to a \texttt{nop} or look at the root logger configuration to see if 
we need to override any parameters. These features cover the needs of controlling 
logging from multiple modules as described in \emph{Design Principle 5}.

In our running example the state manager will intercept the creation of the logger 
on line 2 in \texttt{foo.js}. Since the logger created here is not the root logger
we intercept this construction, set the in-memory log level to 
the overridden (default) \texttt{WARN} level instead of the standard value of \texttt{DETAIL}, 
prevent the modification of the \emph{emit-level} on line 9, and will 
store the newly created logger in a list of subloggers. 

Tracking the list of all created sub-loggers allows a developer to share a 
single logger between several files in the same module. The name parameter in the 
logger constructor is keyed with the logger and, if the same key is used in multiple 
places, the same logger object will be returned.

Finally, the state manager is responsible for maintaining information on the current 
\emph{emit levels}, the enabled/disabled categories, and the sublogger override information. 
Each logger has an independent level at which it can write into the in-memory log but 
the state manager maintains a global set of enabled/disabled categories which each logger 
uses and a global logging level for eventual emit processing. Only the root logger is 
allowed to update the categories and emit levels. 

In our running example the main application has a log statement on lines $12$ and $14$ 
that are in the \texttt{Perf} category and will put a message with the current walltime 
in the log. As the first log statement happens before the \texttt{Perf} category has 
been enabled it will not be processed. However, after enabling the \texttt{Perf} category 
on line $13$ the log operation on line $14$ will be processed and result in a message 
being saved to the in-memory log.

\paragraph{Message Formats}
\noindent
To improve performance and support machine parsing of the log output we 
adopt a \emph{semantic logging} approach where the log call copies the format 
information and message arguments to a secondary location instead of formatting them 
immediately. This implementation choice supports the needs of \emph{Design Principle 2}.
Since the copy operation is low cost this minimizes the 
performance impact on the main thread and allows the formatter to build up a 
parser for all the messages it emits which can be later used to parse the log. 
Modern software development also favors the use of consistent styles and data 
values in the log. Thus, \projn encourages developers to split the logging 
action into two components:
\begin{itemize}
\item Format definition using an \texttt{addFormat} method which takes a format 
string or JSON format object, processes it into an optimized representation, 
and then saves it for later use.
\item Use a previously defined format in a log statement by passing the 
previously generated format identifier and the list of 
arguments for processing.
\end{itemize}

In addition to programmatically processing single log formats, as shown on line 3 
in \autoref{fig:appmain}, we also allow the programmer to load formats in bulk 
from a JSON formatted file. This allows a team to have a unified set of logging 
messages that can be loaded/processed quickly on startup and then used repeatedly 
throughout the applications execution. Once loaded all format objects are saved 
in the \emph{Formats} component in \autoref{fig:arch} where they can be loaded 
as needed when processing a log statement.\\

\noindent
The format for a logger message is:
\begin{lstlisting}[language=JavaScript,basicstyle=\scriptsize]
{
  formatName: string, //name of the format
  formatString: string, //raw format string
  formatterEntries: {
    kind: number, //tag indicating the entry kind
    argPosition?: number, //position in argument list
    expandDepth?: number, //JSON expand depth
    expandLength?: number //JSON expand length
  }[]
}
\end{lstlisting}

This representation allows us to quickly scan and process arguments to a log statement as 
described in the \emph{In-Memory Message  Processing} section. The kind 
information is used for both identifying what type of value is expected 
when formatting an argument, e.g. \texttt{number}, \texttt{string}, etc., 
but we also use it to support \emph{format macros}.

To support the easy/efficient logging on a number of common values that 
are not easily (or cheaply) computable we provide \emph{format macros}. 
Classic examples include adding the current walltime or the hostname as 
part of a log message. In JavaScript these require explicitly calling 
expensive compound API sequences \texttt{new Date().toISOString()} or 
\texttt{require('os').hostname()}. Instead we allow a developer to use 
special macros \texttt{\#walltime}, as seen on line 11 in \autoref{fig:appmain}, 
or \texttt{\#host} in their format 
strings and then the logger has optimized internal paths to get the needed 
values. In these cases the \texttt{kind} field is set to the enumeration 
for the macro and the \texttt{argPosition} is undefined. The list of supported 
macro formatters includes:
\begin{itemize}
  \item \#host -- name of the host
  \item \#app -- name of the root application
  \item \#logger -- name of the logger
  \item \#source -- source location of log statment (file, line)
  \item \#wallclock -- wallclock timestamp (ISO formatted)
  \item \#timestamp -- logical timestamp
  \item \#request   -- the current request id (for http requests)
\end{itemize}

A common logging practice is to include raw objects, formatted as JSON, into the 
message. This is a convenient way to include rich data in a message but can 
lead to unexpectedly excessive logging loads when, what the developer expected to 
be a small object, turns out to be quite large. To prevent this we have a specialized 
JSON-style processor that will bound the depth/length of object expansion during 
formatting. The \texttt{expandDepth} and \texttt{expandLength} arguments provide 
control over this depth/length and can be adjusted in the format string when a 
developer want to capture more (or less) information than what is provided by the 
defaults.

\paragraph{In-Memory Message Processing}
\noindent
The in-memory buffer is implemented as a linked-list of block structures:
\begin{lstlisting}[language=JavaScript,basicstyle=\scriptsize]
{
  tags: Uint8Array,
  data: Float64Array,
  strings: string[],
  properties: map<number, string>
}
\end{lstlisting}

To allow efficient marshalling of the data from our JavaScript logger frontend 
to the C++ N-API code that handles the formatting we encode all values into 
$64$bit based representations (stored in the \texttt{data} property). We use a set 
of enumeration tags (stored in the \texttt{tags} property) to track 
what the kind of the corresponding $64$bit value is. We have special 
handling for string and object property values, described below, that use the 
\texttt{strings} array and the \texttt{properties} map.

When implementing a sematic logging system the key invariant that needs to be 
preserved is that the values of each argument must not be changed between the 
time when the log call happens and when the argument is processed for 
formatting. Certain values including booleans, numbers, and strings, are 
immutable according to the language semantics so we can just copy the 
values/references directly into our in-memory array. However, in cases where the 
argument is a mutable object we must take explicit actions. A simple solution 
would be to JSON \texttt{stringify} the argument immediately, and while this 
prevents mutation and allows semantic formatting, it compromises possible 
performance gains we are looking for. Instead we recursively flatten the object 
into the in-memory buffer with the code below:

\lstinputlisting[language=JavaScript,basicstyle=\scriptsize]{Code/flatten.js}

This code is part of the transition from the formats and logger call arguments 
that is performed in the \emph{Message processing} component shown in \autoref{fig:arch}. This code 
starts off by checking if we are either in a cycle or the depth bound has been 
reached. If either of these occur we put a special tag, \texttt{CycleTag} or 
\texttt{DepthBoundTag} respectively, into the tags array and return. If not we 
continue with the pre-order traversal of the object graph by updating the cycle 
info, adding the special \texttt{LParenTag} to the buffer, and enumerating the 
object properties. For each property we check if the length bound is met, adding 
the special \texttt{LengthBoundTag} and breaking if needed, if not we add the 
property and value information to the in-memory buffer. The property value \texttt{p} 
is a special string value which is very likely to be repeated so we use a map 
from properties to unique numeric identifiers to compress and convert them into 
a number which can be stored in the \texttt{data} component of the in-memory buffer 
via the \texttt{addPropertyEntry} function. The value associated is recursively 
processed via the \texttt{addGeneralEntry} call which switches on the type of the 
value, booleans and numbers are converted directly to \texttt{Float64} representations, 
strings are mapped by index in the \texttt{strings} array, and \texttt{Date} objects 
are converted to $64$bit timestamps using the \texttt{valueOf} method. Similar to 
standard JSON formatting other values are simplified but, instead of just dropping 
them, we use a special \texttt{OpaqueValueTag}. After all the properties have 
been processed we update the cycle tracking information and add a closing 
\texttt{RParenTag}.

To illustrate how this code works in practice consider the case of processing the 
object argument:

\begin{lstlisting}[language=JavaScript,basicstyle=\scriptsize,numbers=none]
{
  f: 3,
  g: 'ok',
  o: { g: (x) => x }
}
\end{lstlisting}

The resulting state of the in-memory buffer is shown in \autoref{fig:inmemory}. 
In this example we can see how the object structure has been flattened into 
the buffer with the \lstinline!'{'! and \lstinline!'}'! tags denoting the bounds 
of each object. Each of the properties has been registered in the map (with a fresh 
numeric identifier) and this is stored in the \texttt{data} array. For example the 
property \lstinline!g! is mapped to $1$ and in both occurrences in the object 
structure the entry in the \texttt{tags} array is set to \lstinline!'p'! for 
property and the value in the \texttt{data} array is set to match the corresponding 
numeric identifier $1$. The numeric and boolean values are mapped in the obvious 
way, directly for the number and to $0$/$1$ for the boolean with the appropriate 
tag values set. Similar to the properties the string value \lstinline!'ok'! is 
mapped to an integer index, index $0$, in the \texttt{strings} array. Finally, 
since functions are not serializable, the value associated with the \lstinline!id! 
property is dropped and we simply store the \texttt{OpaqueValueTag} (\lstinline!'?'!) 
in the corresponding position of the \texttt{tags} array.

\paragraph{Message Staging}
\noindent
The in-memory design allows us to support \emph{Design Principle 3} by buffering a 
window of high detail messages, in case they are needed for diagnostics, and then 
asynchronously filtering and flushing out high level telemetry messages to stable 
storage. Whenever a message is written into the in-memory buffer we do a simple 
\texttt{writeCount} check, to limit the flush rate, on the number of messages written 
since the last flush. If more than this threshold have been written we schedule an 
asynchronous flush process on the event-loop. The flush code filters the messages 
based on the current \emph{emit} level and processes all messages that exceed the 
specified \texttt{age} and \texttt{memory} thresholds. The implementation of the 
filter/process step from~\autoref{fig:arch} is:

\lstinputlisting[language=JavaScript,basicstyle=\scriptsize]{Code/process.js}

This code works by looping over the messages in the in-memory buffer passed in, 
\lstinline!buff!, and will process  messages in the buffer until the 
\lstinline!ageCheck! or \lstinline!sizeCheck! conditions no longer 
hold. These conditions check if a message is older than the specified 
\lstinline!age! measured from the current time and that overall memory 
consumption is less than \lstinline!size! respectively. The intent behind the 
age limit is to prevent the overly eager discarding of log messages that might 
be relevant for debugging. While the intent behind the size condition is to ensure 
that an application which has a heavy burst of logging will not cause excessive 
memory consumption even if the messages have not aged out yet.

\begin{figure}
    \centering
\begin{lstlisting}[basicstyle=\small,numbers=none]
tags: [ {, p, n, p, s, p, {, p, ?, }, } ]
data: [ _, 0, 3, 1, 0, 2, _, 1, _, _, _ ]

strings: [ 'ok' ]
props:   { f -> 0, g -> 1, o -> 2 }

\end{lstlisting}
    \caption{In-Memory buffer processing example}
    \label{fig:inmemory}
\end{figure}

If an issue, currently defined as an unhandled exception or an exit with non-zero code, 
is encountered during execution the logger will immediately flush all the logger 
messages to the serializer regardless of age or level. This ensures that there is maximal 
detail for the developer when trying to diagnose the issue. \projn also supports 
programatic force-flushing of the log, with the \texttt{forceFlush} method, for cases where there 
is an issue that the developer wants to understand but does not result in a hard failure. 

\paragraph{Emit Callback}
\noindent
Once the in-memory buffer has been processed the logger passes the filtered set of 
log messages to the background \emph{Async Formatter} (described in \autoref{sec:nativeimpl}) 
which, when formatting is complete, will default to invoking a callback into the 
JavaScript application. For common cases we provide the simple default callback that 
writes to \texttt{stdout} or, if a \texttt{stream} is provided, to write the logs out through 
it. In the most general case a user can configure the logger with a custom callback, 
called with the formatted log data, which can perform any desired post processing and 
send the data to arbitrary (or multiple) sinks.

\subsection{Native Formatting and Optional Native Emit}
\label{sec:nativeimpl}
The background \emph{Async Formatter} in \autoref{fig:arch} 
is implemented in Native code using the N-API~\cite{NAPI} module. This
code is not part of the GC managed host JavaScript engine so we must fully copy any data needed before starting 
the background processing (a limitation we discuss relaxing in \autoref{sec:runtimesupport}). 
However, once the data copy is done the formatting thread can run in parallel 
to the main JavaScript thread and can use an optimized C++ formatting implementation. This 
allows us to reduce the overall formatting cost and also to move this cost 
entirely off the hot-path of JavaScript execution.

In addition to background formatting \projn also supports background emitting 
shown as the \emph{Async Transport} block in \autoref{fig:arch}. Instead of 
moving formatted data back into the JavaScript engine to output we can directly 
write this logging data directly to a file, \texttt{stdout}, or a remote URL provided at configuration 
time from the native code layer. This 
allows us to skip re-marshaling the formatted data into a JavaScript string as well 
as reduces the number of JavaScript callbacks and associated time spent on the 
main thread there. 

By default the native formatter produces JSON compliant output. However, this 
can be verbose to send and store so we offer serialization format and compression 
options for optimization. In addition to JSON a user can configure the logger 
to format to a simple binary encoding format which is not human readable but 
more compact and computationally efficient to 
encode into. With either format the logger can also be configured to compress the 
formatted data as well using the \texttt{zlib} library already included in 
Node.js core.

\subsection{Logging APIs}
As described in \emph{Design Principle 4} there are frequent cases where a 
simple call to a log statement is insufficient and a developer would normally 
need to add explicit logging-specific logic. To avoid this clutter, and potential 
source of errors, we provide a richer set of logging primitives:
\begin{itemize}
  \item \emph{conditional logging} which allows a user to specify a condition 
  that guards the execution of the log statement. This eliminates the need to 
  introduce logging specific control flow into the code.
  \item \emph{child loggers} which create a logger object that prefixes all log 
  operations called on it with a specified value (used frequently for logging in a 
  subcomponent).
  \item \emph{request specific logging} which allows a developer to set a different 
  logging level and enabled categories for a specific \texttt{RequestID}. This is a 
  common need for cloud-based applications, particularly when participating in a 
  sampling distributed logging system.
  \item \emph{interval bounding} which writes a log message at the start of an interval 
  and accepts a payload which can be accessed when writing the end event for the interval. 
  This allows the transparent, instead of explicit, propagation of the relevant data between 
  the log actions.
\end{itemize}

An example of the utility of these loggers, conditional logging, is in
\autoref{fig:introExample} where the condition on line 14 was introduced 
solely for logging purposes. Using our conditional logging APIs this check 
and log combo can be replaced by a single line \lstinline{logger.warnIf(!ok, "Error...")}.

\subsection{Custom Runtime Implementation}
\label{sec:runtimesupport}
The previous sections described the \projn logger as it can be implemented as a purely 
userspace module in Node.js and as it is publicly available. However, there are 
issues, optimizations, and improvements that require close interaction with the 
runtime and/or compiler. This section describes these and how we have explored their 
implementation in Node-ChakraCore~\cite{NodeChakraCore}, the version of Node.js running the ChakraCore 
JavaScript engine from Microsoft. 

\paragraph{Format and Mutability Checking}
\noindent
Two programming errors that are specific to logging are mismatched arguments used 
for the provided format specifiers and accidental side-effects in logging related 
code. \projn takes the view that logger calls should, if all possible, not cause 
an application failure and instead note invalid arguments in the output formatting. 
Previous work~\cite{tyepcheckprintf} has shown how to include static type 
checking for log arguments as well. A similar approach can be taken to combine 
work on purity analysis~\cite{choipurity,mypurity} to ensure that any code executed 
in a log statement does not modify externally visible state. These features require 
at least support in a linter, such as \emph{eslint}~\cite{eslint}, or integration 
with the language itself.

\paragraph{Zero-Cost Disabled Logging}
\noindent
Developers have low trust that logging disabled by setting levels or categories 
will not continue to impact performance. Thus, projects often experience frequent 
code churn as logging is added for a task and then removed afterwards to avoid 
performance issues. This wastes substantial developer time, creates opportunities 
to introduce accidental regressions, and prevents the development of a comprehensive 
base of logging code in an application. 

To ensure that disabled log statements truely are zero-cost requires cooperation 
with the language spec and the JIT. To avoid parasitic costs of evaluating log 
arguments that will be immediately discarded, like line 8 in \autoref{fig:introExample}, 
we must lazily evaluate them after the level, category, and (optional) condition 
checks have completed. We also want the JIT to be particularly aware of the guards 
around log statements, aggressively optimizing the guard paths, and performing 
dead-code-elimination or motion on computations that are only used for log arguments.

\paragraph{Fast Handling for Strings and Properties}
\noindent
JavaScript object properties and string are frequently occurring values in 
parts of a log message. If we are limited to a purely JavaScript and N-API 
interface we are forced to treat the properties as strings and we must 
defensively copy the strings when processing them in the \emph{emit processor} staging 
phase otherwise the JavaScript engine GC may move them while the formatter is 
accessing the underlying memory creating a data race and corruption. 

Modern JavaScript engines use internal numeric \emph{Property Identifiers} 
instead of strings when dealing with object properties. These are much more 
compact and efficient to process for both the engine and, in our logger, would 
allow us to copy a single integer into our in-memory buffer instead of creating 
our own indexing scheme. Thus, we expose a new 
JavaScript API, \texttt{loggerGetPropertyId}, which returns the 
internal numeric identifier for a property string to use in the message staging. 

To avoid costs associated with data marshaling and copying string data 
in the formatter we need to introduce three APIs. The first is a pair of 
methods, \texttt{loggerRefString} in JavaScript which will tell the JavaScript 
engine that it needs to reference count, flatten, and intern a string (if needed) 
with a unique numeric value (which is returned), and a method \texttt{loggerReleaseString} 
which decrements the reference count and unpins the string if needed. These 
allow us to avoid copies when marshaling the string in the message staging 
phase. As various JavaScript engines use different internal widths for characters 
we add \texttt{getNativeStringCharSize} to determine if strings 
are \texttt{utf8} or \texttt{utf16} encoded. In combination with the methods \texttt{getRawBytes} 
to get the underlying buffer and \texttt{createStringWithBytes} to create a string this allows us to avoid any encoding 
conversions during the formatting. 

\paragraph{Priority Aware I/O Management}
\noindent
The final optimization we look at is to ensure 
that logging related I/O and computation do not interfere with high-priority 
code responding to user actions. In our implementation the message staging 
and uploading of formatted log data is done on the UV event loop. This loop does 
not have any notion of priority so we may accidentally block code responding 
to a user action with code that is processing log data. To avoid this we could 
add a special \emph{log work queue} to the existing Node event loop processing 
algorithm but we believe that the notion of priority is 
fundamentally valuable and should be added to Node explicitly~\cite{asynchjs}. 
This \emph{priority promise} construction makes it trivial to add logging related 
callbacks at a background task level to ensure 
that logging activities are completed in a timely manner without impacting user 
responsiveness.






